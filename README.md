# ğŸš— Traffic Monitor - SystÃ¨me de Monitoring de Trafic Routier en Temps RÃ©el

Projet Big Data : Architecture complÃ¨te de DataLake pour l'ingestion, la persistance et le traitement de donnÃ©es de trafic routier en temps rÃ©el.

![Architecture](https://img.shields.io/badge/Architecture-Kafka%20%2B%20Spark%20%2B%20HDFS-blue)
![Backend](https://img.shields.io/badge/Backend-FastAPI-green)
![Frontend](https://img.shields.io/badge/Frontend-React%20%2B%20Leaflet-orange)
![Status](https://img.shields.io/badge/Status-In%20Development-yellow)

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Technologies](#technologies)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [AgrÃ©gations Spark](#agrÃ©gations-spark)
- [API Documentation](#api-documentation)
- [DÃ©ploiement](#dÃ©ploiement)
- [Contributeurs](#contributeurs)

---

## ğŸ¯ Vue d'ensemble

**Traffic Monitor** est un systÃ¨me de monitoring temps rÃ©el du trafic routier basÃ© sur une architecture Big Data complÃ¨te :

- **Ingestion** : Collecte de donnÃ©es via API TomTom Traffic et stockage dans Kafka
- **Persistance** : HDFS partitionnÃ© pour l'historique et PostgreSQL pour les mÃ©tadonnÃ©es
- **Traitement** : Spark Streaming pour les transformations et agrÃ©gations temps rÃ©el
- **Visualisation** : Dashboard interactif React avec cartes Leaflet

### ğŸ“ Objectifs PÃ©dagogiques

- Architecture DataLake 3 couches (Ingestion â†’ Persistance â†’ Insight)
- Streaming temps rÃ©el avec Kafka & Spark Structured Streaming
- Partitionnement intelligent HDFS
- API REST moderne avec FastAPI
- Dashboard interactif avec React

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION LAYER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  API TomTom Traffic â†’ Kafka Producer â†’ Kafka Topics        â”‚
â”‚  (DonnÃ©es temps rÃ©el)    (Python)      (weather_stream)    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PERSISTENCE LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        Spark Streaming ETL                          â”‚   â”‚
â”‚  â”‚  - Nettoyage donnÃ©es                                â”‚   â”‚
â”‚  â”‚  - Calcul congestion                                â”‚   â”‚
â”‚  â”‚  - DÃ©tection anomalies                              â”‚   â”‚
â”‚  â”‚  - GÃ©nÃ©ration alertes                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                 â”‚                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚        â”‚      HDFS       â”‚   â”‚   PostgreSQL      â”‚         â”‚
â”‚        â”‚  (Parquet)      â”‚   â”‚   (Metadata)      â”‚         â”‚
â”‚        â”‚  PartitionnÃ©:   â”‚   â”‚                   â”‚         â”‚
â”‚        â”‚  /traffic/      â”‚   â”‚  - zones_latest   â”‚         â”‚
â”‚        â”‚  â”œâ”€ raw/        â”‚   â”‚  - incidents      â”‚         â”‚
â”‚        â”‚  â”œâ”€ clean/      â”‚   â”‚  - logs           â”‚         â”‚
â”‚        â”‚  â””â”€ aggregates/ â”‚   â”‚                   â”‚         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INSIGHT LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           FastAPI Backend (Port 8000)                â”‚  â”‚
â”‚  â”‚  - REST API endpoints                                â”‚  â”‚
â”‚  â”‚  - WebSocket pour temps rÃ©el                         â”‚  â”‚
â”‚  â”‚  - Spark queries vers HDFS                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        React Dashboard (Port 5173)                   â”‚  â”‚
â”‚  â”‚  - Carte interactive (React-Leaflet)                 â”‚  â”‚
â”‚  â”‚  - KPIs temps rÃ©el                                   â”‚  â”‚
â”‚  â”‚  - Graphiques (Recharts)                             â”‚  â”‚
â”‚  â”‚  - Alertes & Incidents                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technologies

### Backend & Data Processing
| Technologie | Version | Usage |
|-------------|---------|-------|
| **Python** | 3.11 | Langage principal |
| **FastAPI** | 0.104+ | API REST moderne |
| **Apache Kafka** | 7.5.0 | Message broker temps rÃ©el |
| **Apache Spark** | 3.5.0 | Traitement distribuÃ© |
| **HDFS** | 3.3+ | Stockage distribuÃ© |
| **PostgreSQL** | 15 | Base mÃ©tadonnÃ©es |
| **Uvicorn** | 0.24+ | Serveur ASGI |

### Frontend
| Technologie | Version | Usage |
|-------------|---------|-------|
| **React** | 18+ | Framework UI |
| **Vite** | 5+ | Build tool |
| **React-Leaflet** | 4+ | Cartes interactives |
| **Recharts** | 2+ | Visualisations |
| **Zustand** | 4+ | State management |
| **TailwindCSS** | 3+ | Styling |
| **Axios** | 1+ | HTTP client |

### Infrastructure
| Technologie | Usage |
|-------------|-------|
| **Docker** | Containerisation |
| **Docker Compose** | Orchestration |
| **Zookeeper** | Coordination Kafka |

---

## ğŸ“¦ PrÃ©requis

### Option 1 : Avec Docker (RecommandÃ©)
- Docker Desktop 4.0+
- Docker Compose 2.0+
- 8 GB RAM minimum
- 10 GB espace disque

### Option 2 : Installation Native
- Python 3.11+
- Node.js 18+
- Java 11+ (pour Kafka/Spark)
- PostgreSQL 15+
- Apache Kafka 3.0+
- Apache Spark 3.5+

---

## ğŸš€ Installation

### MÃ©thode 1 : Docker (RecommandÃ©)
```bash
# 1. Cloner le projet
git clone https://github.com/votre-repo/traffic-monitor.git
cd traffic-monitor

# 2. Lancer avec Docker Compose
docker-compose up --build

# 3. Attendre que tous les services dÃ©marrent (30-60s)
# VÃ©rifier : docker-compose ps

# 4. AccÃ©der Ã  l'application
# Frontend: http://localhost:5173
# Backend API: http://localhost:8000/docs
```

### MÃ©thode 2 : Installation Native

#### Backend
```bash
cd backend

# CrÃ©er environnement virtuel
python3.11 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer dÃ©pendances
pip install -r requirements.txt

# Lancer FastAPI
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend
```bash
cd frontend

# Installer dÃ©pendances
npm install

# Lancer en mode dev
npm run dev
```

#### Infrastructure (Kafka, Zookeeper, PostgreSQL)
```bash
# DÃ©marrer Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# DÃ©marrer Kafka
bin/kafka-server-start.sh config/server.properties

# CrÃ©er topics
bin/kafka-topics.sh --create --topic weather_stream \
  --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

bin/kafka-topics.sh --create --topic weather_transformed \
  --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

---

## ğŸ’» Utilisation

### DÃ©marrage Rapide
```bash
# Avec Docker
docker-compose up -d

# VÃ©rifier que tout tourne
docker-compose ps

# Voir les logs
docker-compose logs -f backend
```

### AccÃ¨s aux Services

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:5173 | Dashboard React |
| **Backend API** | http://localhost:8000 | API REST |
| **API Docs** | http://localhost:8000/docs | Documentation Swagger |
| **Kafka** | localhost:9092 | Broker Kafka |
| **PostgreSQL** | localhost:5432 | Base de donnÃ©es |

### Commandes Utiles
```bash
# ArrÃªter tous les services
docker-compose down

# ArrÃªter et supprimer les volumes
docker-compose down -v

# RedÃ©marrer un service
docker-compose restart backend

# Voir les logs
docker-compose logs -f frontend

# Entrer dans un container
docker-compose exec backend bash
```

---

## ğŸ“ Structure du Projet
```
traffic-monitor/
â”œâ”€â”€ backend/                    # API FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # Point d'entrÃ©e
â”‚   â”‚   â”œâ”€â”€ api/               # Routes API
â”‚   â”‚   â”œâ”€â”€ models/            # ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ services/          # Logique mÃ©tier
â”‚   â”‚   â””â”€â”€ core/              # Configuration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/                   # Application React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Map/           # Composants carte
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard/     # KPIs & widgets
â”‚   â”‚   â”‚   â””â”€â”€ Charts/        # Graphiques
â”‚   â”‚   â”œâ”€â”€ services/          # API calls
â”‚   â”‚   â”œâ”€â”€ store/             # Zustand store
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ spark/                      # Jobs Spark
â”‚   â”œâ”€â”€ kafka_producer.py      # Producteur TomTom
â”‚   â”œâ”€â”€ streaming_etl.py       # ETL Spark Streaming
â”‚   â””â”€â”€ batch_aggregates.py    # AgrÃ©gations batch
â”‚
â”œâ”€â”€ docker-compose.yml          # Orchestration
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ“Š AgrÃ©gations Spark

### AgrÃ©gations Temps RÃ©el (Spark Streaming)

#### 1. Calcul du Niveau de Congestion
```python
# Formule : (1 - vitesse_actuelle / vitesse_libre) Ã— 100
congestion_level = (1 - col("current_speed") / col("free_flow_speed")) * 100
```

#### 2. Classification Statut
- **Fluide** : congestion < 20%
- **ModÃ©rÃ©** : 20% â‰¤ congestion < 50%
- **Dense** : 50% â‰¤ congestion < 80%
- **BloquÃ©** : congestion â‰¥ 80%

#### 3. AgrÃ©gation par FenÃªtre (5 minutes)
```python
df_5min = df_stream.groupBy(
    window(col("timestamp"), "5 minutes"),
    col("zone_id")
).agg(
    avg("current_speed").alias("avg_speed"),
    min("current_speed").alias("min_speed"),
    max("current_speed").alias("max_speed"),
    avg("congestion_level").alias("avg_congestion")
)
```

### AgrÃ©gations Batch (HDFS)

#### 4. Comparaison Historique
```python
# Comparer vitesse actuelle vs moyenne historique
df_comparison = df_realtime.join(df_historical, "zone_id")
```

#### 5. DÃ©tection d'Anomalies
```python
# Chute brutale de vitesse (> 25 km/h)
df_incidents = df.withColumn(
    "speed_drop",
    col("current_speed") - lag("current_speed", 1).over(windowSpec)
).filter(col("speed_drop") < -25)
```

#### 6. Patterns Temporels
```python
# Heures de pointe par zone
df_peak_hours = df.groupBy("zone_id", hour("timestamp")).agg(
    avg("congestion_level")
).filter(col("avg_congestion") > 60)
```

---

## ğŸ”Œ API Documentation

### Endpoints Principaux

#### GET `/api/zones/live`
Retourne les donnÃ©es temps rÃ©el de toutes les zones surveillÃ©es.

**RÃ©ponse :**
```json
[
  {
    "zone_id": "1",
    "zone_name": "Champs-Ã‰lysÃ©es",
    "latitude": 48.8698,
    "longitude": 2.3078,
    "current_speed": 35.5,
    "free_flow_speed": 50.0,
    "congestion_level": 29.0,
    "status": "ModÃ©rÃ©",
    "timestamp": "2025-11-19T15:30:00"
  }
]
```

#### GET `/api/zones/top-congested?limit=5`
Top zones les plus congestionnÃ©es.

#### GET `/api/aggregates/stats`
Statistiques globales du rÃ©seau.

**RÃ©ponse :**
```json
{
  "total_zones": 30,
  "fluide": 8,
  "modere": 12,
  "dense": 7,
  "bloque": 3,
  "avg_global_speed": 42.5,
  "avg_global_congestion": 48.3
}
```

#### GET `/api/zones/history/{zone_id}?hours=24`
Historique d'une zone sur N heures.

### WebSocket

#### WS `/ws/live`
Stream temps rÃ©el des donnÃ©es de trafic.
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/live');
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data.zones);
};
```

---

## ğŸ¨ Dashboard Features

### ğŸ—ºï¸ Carte Interactive
- **Marqueurs colorÃ©s** selon niveau de congestion
- **Popups** avec dÃ©tails zone
- **Zoom** et navigation fluide
- **Actualisation** automatique toutes les 10s

### ğŸ“Š KPIs Temps RÃ©el
- Vitesse moyenne globale
- Taux de congestion
- Nombre de zones surveillÃ©es
- Zones fluides vs bloquÃ©es

### ğŸ“ˆ Graphiques
- Top 5 zones congestionnÃ©es (bar chart)
- Ã‰volution vitesse (timeline)
- Distribution statuts (pie chart)
- Heatmap congestion par heure

### ğŸš¨ Alertes
- DÃ©tection incidents (chute vitesse)
- Congestion > 80%
- Comparaison historique

---

## ğŸ§ª Tests

### Backend
```bash
cd backend
pytest tests/
```

### Frontend
```bash
cd frontend
npm run test
```

### API (Manuel)
```bash
# Test endpoint
curl http://localhost:8000/api/zones/live

# Test avec jq (pretty print)
curl http://localhost:8000/api/zones/live | jq
```

---

## ğŸš¢ DÃ©ploiement

### Docker Hub
```bash
# Build et push images
docker build -t votre-user/traffic-backend:latest ./backend
docker push votre-user/traffic-backend:latest

docker build -t votre-user/traffic-frontend:latest ./frontend
docker push votre-user/traffic-frontend:latest
```

### Production
```bash
# Utiliser docker-compose en prod
docker-compose -f docker-compose.prod.yml up -d
```

---

## ğŸ” Variables d'Environnement

### Backend (`.env`)
```env
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/traffic
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
TOMTOM_API_KEY=votre_clÃ©_api
ENVIRONMENT=production
```

### Frontend (`.env`)
```env
VITE_API_URL=http://localhost:8000/api
VITE_WS_URL=ws://localhost:8000/ws
```

---

## ğŸ› Troubleshooting

### Kafka ne dÃ©marre pas
```bash
# VÃ©rifier les logs
docker-compose logs kafka

# Nettoyer et redÃ©marrer
docker-compose down -v
docker-compose up kafka
```

### Port dÃ©jÃ  utilisÃ©
```bash
# Trouver et tuer processus sur port 8000
lsof -ti:8000 | xargs kill -9
```

### Frontend ne se connecte pas au backend
1. VÃ©rifier CORS dans `backend/app/main.py`
2. VÃ©rifier `VITE_API_URL` dans `.env`
3. Tester API : `curl http://localhost:8000/health`

---

## ğŸ“š Documentation

- **Architecture** : [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)
- **API Reference** : http://localhost:8000/docs
- **Spark Jobs** : [docs/SPARK.md](docs/SPARK.md)
- **DÃ©ploiement** : [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)

---

## ğŸ‘¥ Contributeurs

- **Eva Depaepe** 
- **Emilie Delrue** 

---



